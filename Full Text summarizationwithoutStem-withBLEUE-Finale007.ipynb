{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grave-richardson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "israeli-department",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\ruba\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ruba\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\ruba\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\ruba\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\ruba\\anaconda3\\lib\\site-packages (from nltk) (2021.3.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in c:\\users\\ruba\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\ruba\\appdata\\roaming\\python\\python38\\site-packages (from rouge) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wrapped-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "successful-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/Ruba/Downloads/Reviews.csv\",nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "higher-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dense-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88421 entries, 0 to 99999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      88421 non-null  int64 \n",
      " 1   ProductId               88421 non-null  object\n",
      " 2   UserId                  88421 non-null  object\n",
      " 3   ProfileName             88421 non-null  object\n",
      " 4   HelpfulnessNumerator    88421 non-null  int64 \n",
      " 5   HelpfulnessDenominator  88421 non-null  int64 \n",
      " 6   Score                   88421 non-null  int64 \n",
      " 7   Time                    88421 non-null  int64 \n",
      " 8   abstract                88421 non-null  object\n",
      " 9   Text                    88421 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "continuous-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "conventional-there",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ruba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unlikely-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "overhead-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "#porter=PorterStemmer()\n",
    "sb_stem =SnowballStemmer(\"english\")\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(sb_stem.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "according-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning the text , lower case , removing commas ... etc\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prescribed-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "medieval-assurance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "basic-island",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "loose-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_abstract = []\n",
    "for t in data['abstract']:\n",
    "    cleaned_abstract.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "golden-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy',\n",
       " 'nice taffy',\n",
       " 'great just as good as the expensive brands',\n",
       " 'wonderful tasty taffy',\n",
       " 'yay barley',\n",
       " 'healthy dog food']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_abstract[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "direct-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore values of text / abstract after cleaning process \n",
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_abstract']=cleaned_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "saved-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty spaces and NA ones\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accredited-technician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# find the length of sentences in each TEXT / Summay to know the MIN.MAX ranges length\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "abstract_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_abstract']:\n",
    "      abstract_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'abstract':abstract_word_count})\n",
    "\n",
    "length_df.hist(bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incomplete-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the length of MAX \n",
    "max_text_len=30\n",
    "max_abstract_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "coral-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the shorter ones than the MAX (max_text_len) limite above (remove anomalies to enhance the model)\n",
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_abstract=np.array(data['cleaned_abstract'])\n",
    "\n",
    "short_text=[]\n",
    "short_abstract=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_abstract[i].split())<=max_abstract_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_abstract.append(cleaned_abstract[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'abstract':short_abstract})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bearing-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add START and END special tokens (StartTok EndToken)\n",
    "df['abstract'] = df['abstract'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "superb-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data 90/10 using train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_validate,y_train,y_validate=train_test_split(np.array(df['text']),np.array(df['abstract']),test_size=0.2,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "smart-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPU_train, EPU_test = train_test_split(np.array(df['text']),np.array(df['abstract']),test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "macro-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Tokenizer \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on x_train data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "decimal-optimization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rare words in vocabulary: 0.6600245898164243\n",
      "Total Coverage of rare words: 0.031248176630529916\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# find the least used words by count limit here is 4times\n",
    "threshold=4 \n",
    "\n",
    "count=0\n",
    "tot_count=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_count=tot_count+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<threshold):\n",
    "        count=count+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"Number of rare words in vocabulary:\",(count/tot_count))\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "excellent-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer(num_words=tot_count-count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ongoing-reproduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8019\n"
     ]
    }
   ],
   "source": [
    "print(tot_count-count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "registered-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training x_vocabulary data [ tokenizer-->texts_to_sequences--->pad_sequences]\n",
    "words_count=tot_count-count #6716\n",
    "x_tokenizer = Tokenizer(num_words=6716) \n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "#convert text sequences into integer sequences texts_to_sequences\n",
    "x_train_seq    =   x_tokenizer.texts_to_sequences(x_train) \n",
    "x_validate_seq   =   x_tokenizer.texts_to_sequences(x_validate)\n",
    "\n",
    "#post padding  zero upto maximum length to unify the sentences lengths   \n",
    "x_train    =   pad_sequences(x_train_seq,  maxlen=max_text_len, padding='post')\n",
    "x_validate   =   pad_sequences(x_validate_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_vocabulary   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beginning-subscriber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6717"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "czech-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "chubby-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rare words in vocabulary: 0.786850969915205\n",
      "Total Coverage of rare words: 0.05761720726007163\n"
     ]
    }
   ],
   "source": [
    "threshold=6\n",
    "\n",
    "count=0\n",
    "tot_count=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_count=tot_count+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<threshold):\n",
    "        count=count+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"number of rare words in vocabulary:\",(count/tot_count))\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "collectible-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1835\n"
     ]
    }
   ],
   "source": [
    "words_count=tot_count-count\n",
    "print(words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "comparative-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on y_tokenizer data [ tokenizer-->texts_to_sequences--->pad_sequences]\n",
    "\n",
    "words_count=tot_count-count\n",
    "y_tokenizer = Tokenizer(num_words=words_count) \n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "#convert text sequences into integer sequences using texts_to_sequences\n",
    "y_train_seq    =   y_tokenizer.texts_to_sequences(y_train) \n",
    "y_validate_seq   =   y_tokenizer.texts_to_sequences(y_validate) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_train    =   pad_sequences(y_train_seq, maxlen=max_abstract_len, padding='post')\n",
    "y_validate   =   pad_sequences(y_validate_seq, maxlen=max_abstract_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_vocabulary  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "macro-steal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37744, 37744)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_train) # those must be equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eleven-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "special-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#K.clear_session()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "needed-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete shot words\n",
    "\n",
    "ind=[]\n",
    "for i in range(len(y_validate)):\n",
    "    cnt=0\n",
    "    for j in y_validate[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_validate=np.delete(y_validate,ind, axis=0)\n",
    "x_validate=np.delete(x_validate,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "interracial-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Attention\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "senior-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aggressive-wholesale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      671700      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    183600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 1836)   1103436     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,543,836\n",
      "Trainable params: 4,543,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building the Encoder model where it has Embedding-->3 LSTM Layers---> Attention Layer---> please review .H5 file for more info\n",
    "\n",
    "from keras import backend as K \n",
    "#K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_vocabulary, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#building the decoder model where it has Embedding-->3 LSTM Layers---> Attention Layer--->  please review .H5 file for more info\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_vocabulary, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_vocabulary, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "disturbed-virgin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.dense_attention.Attention"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "chemical-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "grave-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
    "es = EarlyStopping(patience=1, monitor='val_loss', restore_best_weights=True) #accuracy, loss, val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "forbidden-drawing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "295/295 [==============================] - 532s 2s/step - loss: 3.3619 - val_loss: 2.5959\n",
      "Epoch 2/16\n",
      "295/295 [==============================] - 556s 2s/step - loss: 2.5374 - val_loss: 2.4800\n",
      "Epoch 3/16\n",
      "295/295 [==============================] - 541s 2s/step - loss: 2.3948 - val_loss: 2.3945\n",
      "Epoch 4/16\n",
      "295/295 [==============================] - 556s 2s/step - loss: 2.3135 - val_loss: 2.3341\n",
      "Epoch 5/16\n",
      "295/295 [==============================] - 514s 2s/step - loss: 2.2388 - val_loss: 2.2789\n",
      "Epoch 6/16\n",
      "295/295 [==============================] - 515s 2s/step - loss: 2.1708 - val_loss: 2.1935\n",
      "Epoch 7/16\n",
      "295/295 [==============================] - 522s 2s/step - loss: 2.0669 - val_loss: 2.1413\n",
      "Epoch 8/16\n",
      "295/295 [==============================] - 523s 2s/step - loss: 1.9984 - val_loss: 2.1096\n",
      "Epoch 9/16\n",
      "295/295 [==============================] - 524s 2s/step - loss: 1.9262 - val_loss: 2.0816\n",
      "Epoch 10/16\n",
      "295/295 [==============================] - 527s 2s/step - loss: 1.8517 - val_loss: 2.0548\n",
      "Epoch 11/16\n",
      "295/295 [==============================] - 520s 2s/step - loss: 1.7992 - val_loss: 2.0426\n",
      "Epoch 12/16\n",
      "295/295 [==============================] - 520s 2s/step - loss: 1.7472 - val_loss: 2.0346\n",
      "Epoch 13/16\n",
      "295/295 [==============================] - 517s 2s/step - loss: 1.6924 - val_loss: 2.0362\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,\n",
    "                  epochs=16,callbacks=[es],batch_size=128, \n",
    "                  validation_data=([x_validate,y_validate[:,:-1]], y_validate.reshape(y_validate.shape[0],y_validate.shape[1], 1)[:,1:]))\n",
    "model.save('encoder_decoder_17.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "returning-stand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "involved-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-cutting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "antique-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "### inference layer\n",
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "material-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ prediction Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "latin-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference model \n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_abstract_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "accomplished-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function takes sequences and return them to original abstract \n",
    "def seq2abstract(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "#this function takes sequences and return them to original Text \n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "consistent-translator",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: fog chaser great bold body taste unlike brands leave harsh taste great product recommend \n",
      "Original abstract: great taste \n",
      "Predicted abstract:  great coffee\n",
      "\n",
      "\n",
      "Review: fish great fresh sea black years like remembered thank reminds home ordering fish \n",
      "Original abstract: great fish \n",
      "Predicted abstract:  great taste\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing some predictions \n",
    "\n",
    "for i in range(0,2):\n",
    "    print(\"Review:\",seq2text(x_train[i]))\n",
    "    print(\"Original abstract:\",seq2abstract(y_train[i]))\n",
    "    print(\"Predicted abstract:\",decode_sequence(x_train[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "better-going",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: simply bar simply fantastic love vegan high protein helpful need find alternative protein sources also provide amazing flavors favorite peanut butter one \n",
      "Original summary: simply awesome \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: longer find flavored tea stores amazon place get thanks amazon \n",
      "Original summary: raspberry tea \n",
      "Predicted summary:  great tea\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing some predictions \n",
    "for i in range(0,2):\n",
    "    print(\"Review:\",seq2text(x_validate[i]))\n",
    "    print(\"Original summary:\",seq2abstract(y_validate[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_validate[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "visible-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_seq = data[['abstract', 'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "reflected-ribbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88354"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EPU_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sound-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_train, EPU_test = train_test_split(EPU_seq, test_size=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "elder-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79518, 2)\n",
      "(8836, 2)\n"
     ]
    }
   ],
   "source": [
    "print(EPU_train.shape)\n",
    "print(EPU_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "legitimate-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1747, 1940, 1, 316, 770, 6, 807, 212, 691, 2217, 6, 1, 5, 38]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "earned-characterization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66852                                              Extremely Good\n",
       "57579                                                 Over Priced\n",
       "58849                                                  Yam treats\n",
       "21264                                               Teenie Weenie\n",
       "93068    Yum... using leftover cooked roast chicken in the fridge\n",
       "                                   ...                           \n",
       "26595                                          What a great idea!\n",
       "33029                                 I like it but my kids don't\n",
       "39126                                                        bpa?\n",
       "40041                                  Thought I was going to die\n",
       "63721                                       It Just Wasn't For Me\n",
       "Name: abstract, Length: 79518, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPU_train['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "israeli-outdoors",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37744,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPU_train['Text'][:37744].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sublime-rachel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37744, 30)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "eleven-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### this section I start using BLEU + ROUGE for Evaluation \n",
    "\n",
    "\n",
    "EPU_train['Text'][:37744] = [decode_sequence(sequence.reshape(1, max_text_len)) for sequence in x_train]\n",
    "\n",
    "EPU_train.to_csv('EPU complete_train_full01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "upset-wages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9158, 30)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dress-cameroon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' best olive oil'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(x_validate[2000].reshape(1, max_text_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "innovative-spirit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79518,)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPU_train['Text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "developed-relation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8836,)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPU_test['Text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "centered-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the shape to match here \n",
    "EPU_test['Text'][:8836] = [decode_sequence(sequence.reshape(1, max_text_len)) for sequence in x_validate[:8836]]\n",
    "EPU_test.to_csv('EPU complete_test_full01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "floating-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save them and read to array \n",
    "#EPU_train_full = pd.read_csv('complete_train_full00001.csv')\n",
    "EPU_test_full = pd.read_csv('complete_test_full00001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "tired-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "#test_df02 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "pregnant-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [seq2text(x_validate[i]) for i in range(len(x_validate))]\n",
    "headlines = [seq2abstract(y_validate[i]) for i in range(len(y_validate))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "typical-commander",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1, 247,  40, ...,   0,   0,   0],\n",
       "       [  1, 547,  14, ...,   0,   0,   0],\n",
       "       [  1,  16,   2, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  1,  19,   4, ...,   0,   0,   0],\n",
       "       [  1,  40, 314, ...,   0,   0,   0],\n",
       "       [  1, 174,  89, ...,   2,   0,   0]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "respected-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_validate --test_sequences_headline\n",
    "#x_validate--test_sequences_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "remarkable-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Text'] = sequences\n",
    "test_df['abstract'] = headlines\n",
    "test_df['Headline_Gen'] = EPU_test_full['Headline_Gen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "artistic-suffering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,  247,   40, ...,    0,    0,    0],\n",
       "       [   1,  547,   14, ...,    0,    0,    0],\n",
       "       [   1,   16,    2, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1,    3,   52, ...,    0,    0,    0],\n",
       "       [   1,    9,   17, ...,    0,    0,    0],\n",
       "       [   1, 1619,   91, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "accurate-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_train_full = pd.read_csv('complete_train_full00001.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "environmental-functionality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>Headline_Gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66852</td>\n",
       "      <td>Extremely Good</td>\n",
       "      <td>great coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57579</td>\n",
       "      <td>Over Priced</td>\n",
       "      <td>great taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58849</td>\n",
       "      <td>Yam treats</td>\n",
       "      <td>not bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21264</td>\n",
       "      <td>Teenie Weenie</td>\n",
       "      <td>great coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93068</td>\n",
       "      <td>Yum... using leftover cooked roast chicken in the fridge</td>\n",
       "      <td>great rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79513</th>\n",
       "      <td>26595</td>\n",
       "      <td>What a great idea!</td>\n",
       "      <td>Probiotics and cereal in one - a great idea!!! My twins love this cereal and so do I!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79514</th>\n",
       "      <td>33029</td>\n",
       "      <td>I like it but my kids don't</td>\n",
       "      <td>I think it tastes great but my kids don't like the way it looks or tastes.  I'll drink it and use it in smoothies for myself, happily.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79515</th>\n",
       "      <td>39126</td>\n",
       "      <td>bpa?</td>\n",
       "      <td>Muir Glen cans are lined in plastic and leach Bisphenol A. Too bad because this was a great product and was a standard in my household. My initial conversations with them they contradicted this fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79516</th>\n",
       "      <td>40041</td>\n",
       "      <td>Thought I was going to die</td>\n",
       "      <td>Tried this sauce on a chip, about four drops worth, half an hour later i was laying on the floor in the bathroom with the thought and feeling i was dying.. I was warned to only take a little drop....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79517</th>\n",
       "      <td>63721</td>\n",
       "      <td>It Just Wasn't For Me</td>\n",
       "      <td>I found this drink to be bitter, sharp, and almost flavorless. I was very surprised after really liking another flavor in this brand (Maybe I got a bad can?). I even had my husband try it to share...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79518 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                  abstract  \\\n",
       "0           66852                                            Extremely Good   \n",
       "1           57579                                               Over Priced   \n",
       "2           58849                                                Yam treats   \n",
       "3           21264                                             Teenie Weenie   \n",
       "4           93068  Yum... using leftover cooked roast chicken in the fridge   \n",
       "...           ...                                                       ...   \n",
       "79513       26595                                        What a great idea!   \n",
       "79514       33029                               I like it but my kids don't   \n",
       "79515       39126                                                      bpa?   \n",
       "79516       40041                                Thought I was going to die   \n",
       "79517       63721                                     It Just Wasn't For Me   \n",
       "\n",
       "                                                                                                                                                                                                  Headline_Gen  \n",
       "0                                                                                                                                                                                                 great coffee  \n",
       "1                                                                                                                                                                                                  great taste  \n",
       "2                                                                                                                                                                                                      not bad  \n",
       "3                                                                                                                                                                                                 great coffee  \n",
       "4                                                                                                                                                                                                   great rice  \n",
       "...                                                                                                                                                                                                        ...  \n",
       "79513                                                                                                                    Probiotics and cereal in one - a great idea!!! My twins love this cereal and so do I!  \n",
       "79514                                                                   I think it tastes great but my kids don't like the way it looks or tastes.  I'll drink it and use it in smoothies for myself, happily.  \n",
       "79515  Muir Glen cans are lined in plastic and leach Bisphenol A. Too bad because this was a great product and was a standard in my household. My initial conversations with them they contradicted this fa...  \n",
       "79516  Tried this sauce on a chip, about four drops worth, half an hour later i was laying on the floor in the bathroom with the thought and feeling i was dying.. I was warned to only take a little drop....  \n",
       "79517  I found this drink to be bitter, sharp, and almost flavorless. I was very surprised after really liking another flavor in this brand (Maybe I got a bad can?). I even had my husband try it to share...  \n",
       "\n",
       "[79518 rows x 3 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPU_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "piano-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "personalized-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [seq2text(x_train[i]) for i in range(len(x_train))]\n",
    "headlines = [seq2abstract(y_train[i]) for i in range(len(y_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "legitimate-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Text'] = sequences\n",
    "train_df['abstract'] = headlines\n",
    "train_df['Headline_Gen'] = EPU_train_full['Headline_Gen'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "tutorial-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_test_full_clean = test_df\n",
    "EPU_train_full_clean = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "concerned-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_test_full_clean.to_csv('EPU_complete_train_full_FIXED.csv')\n",
    "EPU_train_full_clean.to_csv('EPU_complete_test_full_FIXED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "polish-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_train_full = pd.read_csv('EPU_complete_train_full_FIXED.csv')\n",
    "EPU_test_full = pd.read_csv('EPU_complete_test_full_FIXED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "corrected-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "def rouge_scoring(row):\n",
    "\n",
    "    reference = str(row['abstract'])\n",
    "    candidate = str(row['Headline_Gen'])\n",
    "    score = rouge.get_scores(candidate, reference)[0]['rouge-1']['r']\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "opened-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_train_full['ROUGE'] = EPU_train_full.apply(lambda row: rouge_scoring(row), axis=1)\n",
    "EPU_test_full['ROUGE'] = EPU_test_full.apply(lambda row: rouge_scoring(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "classical-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_scoring(row):\n",
    "\n",
    "    reference = row['abstract']\n",
    "    candidate = row['Headline_Gen']\n",
    "\n",
    "    reference = [str(reference).split()]\n",
    "    candidate = str(candidate).split()\n",
    "    score = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "intense-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_train_full['BLEU'] = EPU_train_full.apply(lambda row: bleu_scoring(row), axis=1)\n",
    "EPU_test_full['BLEU'] = EPU_test_full.apply(lambda row: bleu_scoring(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_20(row):\n",
    "\n",
    "    first_20 = ' '.join([word for i, word in enumerate(row['Text'].split()) if i <=20])\n",
    "    return first_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "popular-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_test_full['Baseline_ROUGE'] = EPU_test_full.apply(lambda row: rouge_scoring(row), axis=1)\n",
    "EPU_test_full['Baseline_BLEU'] = EPU_test_full.apply(lambda row: bleu_scoring(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "experienced-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPU_test_full.to_csv('complete_train_full_FIXED_W_SCORES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "conservative-certification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37744,)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPU_test_full['abstract'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "disturbed-shape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37744, 30)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "transsexual-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9158, 30)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "green-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37744, 7)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:,:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "headed-switzerland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47181,)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-context",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-prize",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-instruction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-motivation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-course",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-corporation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
